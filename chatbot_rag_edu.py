# -*- coding: utf-8 -*-
"""chatbot_rag_edu.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18d3ucyU2blSAE9RcjuNlB8j1xqqr1Ney

## **Извлечение вопросов**
"""

import json
import zipfile

questions = []

# Открытие и обработка архива
with zipfile.ZipFile('chats.zip', 'r') as zip_ref:
    for file_name in zip_ref.namelist():
        if file_name.endswith('.json'):
            with zip_ref.open(file_name, 'r') as file:
                data = json.load(file)

                # Работа с каждым сообщением из чата
                for message in data.get('messages', []):
                    # Извлечение только текста
                    if message.get('type') == 'message' and isinstance(message.get('text'), str):
                        text = message['text']
                        # Отбор вопросов
                        if "?" in text:
                            questions.append(text.lower())

print(questions)

"""## **Предобработка текста**"""

import nltk
import re
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from natasha import (
    Segmenter,
    MorphVocab,
    NewsEmbedding,
    NewsMorphTagger,
    Doc
)

nltk.download('stopwords')
nltk.download('punkt')

stopwords = set(stopwords.words("russian"))

# Общая функция для обработки текста
def preprocess_text(questions):
    # Этап 1: Чистка текста
    def clean(sentence):
        # Удаляем спецсимволы
        sentence = re.sub(r'[^\w\s]', '', sentence)
        # Токенизация
        words = word_tokenize(sentence)
        # Фильтрация стоп-слов
        filtered_words = [word for word in words if word not in stopwords]
        return " ".join(filtered_words)

    # Очистка вопросов от спецсимволов и стоп-слов
    cleaned_questions_2 = [clean(question) for question in questions]
    cleaned_questions = [string for string in cleaned_questions_2 if string]

    # Этап 2: Лемматизация
    segmenter = Segmenter()
    morph_vocab = MorphVocab()
    emb = NewsEmbedding()
    morph_tagger = NewsMorphTagger(emb)

    # Функция для лемматизации одного предложения
    def lemmatize_sentence(sentence):
        doc = Doc(sentence)
        doc.segment(segmenter)
        doc.tag_morph(morph_tagger)
        for token in doc.tokens:
            token.lemmatize(morph_vocab)
        return ' '.join([token.lemma for token in doc.tokens])

    # Лемматизация очищенных вопросов
    final_sentences = [lemmatize_sentence(sentence) for sentence in cleaned_questions]

    # Этап 3: Удаление чисел и слов, написанных латиницей
    def remove_numbers_and_latin_words(sentence):
        sentence = re.sub(r'\d+', '', sentence)
        sentence = re.sub(r'[a-zA-Z]+', '', sentence)
        return sentence

    # Применение функции ко всем предложениям
    cleaned_sentences = [remove_numbers_and_latin_words(sentence) for sentence in final_sentences]

    return cleaned_sentences

processed_text = preprocess_text(questions)
print(processed_text)

"""## **Выделение ключевых слов**"""

import re
import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer

# Список слов, которые мы дополнительно удаляем, чтобы получить релевантные данные
words_out = ['маргарита', 'быть', 'просто', 'день', 'такой', 'сделать', 'добрый', 'пожалуйста', 'это', 'делать',
             'задание', 'здравствовать', 'здравствуйте', 'подскажите', 'нужный', 'мочь', 'вопрос', 'почему']

# Вычисление TF-IDF
vectorizer = TfidfVectorizer(stop_words=words_out, max_df=0.85, min_df=2)
tfidf_matrix = vectorizer.fit_transform(processed_text)

# Получаем слова и их TF-IDF значения
feature_names = vectorizer.get_feature_names_out()
tfidf_values = tfidf_matrix.toarray().sum(axis=0)

# Создаем DataFrame для анализа
tfidf_df = pd.DataFrame({
 'word': feature_names,
 'tfidf': tfidf_values
})

# Сортируем по убыванию TF-IDF и выбираем количество ключевых слов
N = 5
top_keywords = tfidf_df.sort_values(by='tfidf', ascending=False).head(N)

print("Ключевые слова для всего текста:")
print(top_keywords)

# Визуализация
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 5))
plt.barh(top_keywords['word'], top_keywords['tfidf'], color='skyblue')
plt.xlabel('Значение TF-IDF')
plt.title('Ключевые слова при помощи TF-IDF')
plt.grid(axis='x')
plt.show()

"""## **Создание векторизированной базы данных**"""

from docx import Document
import io
import zipfile
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np

# Функция для извлечения документов из архива с их именами
def extract_archive_documents(archive_path):
    documents = {}

    with zipfile.ZipFile(archive_path, 'r') as archive:
        for file_name in archive.namelist():
            document_data = archive.read(file_name)
            doc = Document(io.BytesIO(document_data))
            paragraphs = [paragraph.text.strip() for paragraph in doc.paragraphs]
            # Удаляем пустые строки и сохраняем с именем файла (без расширения)
            cleaned = [line for line in paragraphs if line.strip()]
            doc_name = file_name.split('.')[0]  # Удаляем расширение .docx
            documents[doc_name] = cleaned

    return documents

# Загрузка модели для эмбеддингов
model = SentenceTransformer('all-MiniLM-L6-v2')

# Создание словаря для хранения индексов FAISS и очищенных текстов
vector_databases = {}

# Обработка архива
archive_path = 'data_base.zip'
documents = extract_archive_documents(archive_path)

# Создание отдельной векторной базы для каждого документа
for doc_name, text in documents.items():
    # Векторизация текста
    embeddings = model.encode(text, convert_to_numpy=True)

    # Создание индекса FAISS
    dim = embeddings.shape[1]
    index = faiss.IndexFlatIP(dim)
    index.add(embeddings)

    # Сохраняем индекс и оригинальный текст
    vector_databases[doc_name] = {
        'index': index,
        'text': text
    }

# Функция для поиска информации по названию дисциплины
def answer_information(discipline_name, query=None):
    if discipline_name not in vector_databases:
        return f"Дисциплина '{discipline_name}' не найдена"

    db = vector_databases[discipline_name]

    # Если запрос не указан, возвращаем весь документ
    if query is None:
        return "\n".join(db['text'])

    # Если запрос указан, ищем наиболее релевантный абзац
    embedding = model.encode([query], convert_to_numpy=True)
    D, I = db['index'].search(embedding, k=1)

    return db['text'][I[0][0]]

# Функция для извлечения релевантной информации из базы данных
def answer_information(discipline_name, query=None, context_size=5):
    if discipline_name not in vector_databases:
        return f"Дисциплина '{discipline_name}' не найдена"

    # Извлечение нужного документа по названию дисциплины
    db = vector_databases[discipline_name]

    if query is None:
        return "\n".join(db['text'])

    # Определение наиболее близкого семантически предложения (из бд) к запросу
    embedding = model.encode([query], convert_to_numpy=True)
    D, I = db['index'].search(embedding, k=1)

    # Захват контекстного окна
    start_idx = max(0, I[0][0] - context_size)
    end_idx = min(len(db['text']), I[0][0] + context_size + 1)

    return "\n\n".join(db['text'][start_idx:end_idx])

answer_information('Цифровая грамотность', 'сколько минут длится экзамен?')

"""## **Функция для обращения к ИИ**"""

from openai import OpenAI
import json

client = OpenAI(api_key="key", base_url="https://api.deepseek.com") # Ключ удален в целях безопасности

# Промпт для обращения к языковой модели
def llm_inference(request, help_information):
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {
                    # В роли кого выступает модель
                    "role": "system",
                    "content": "Ты - молодая девушка, которая работает ассистенткой в университете. Отвечай кратко и точно. Отвечай эмпатично: поддерживай собеседника."
                },
                {
                    # Какой запрос поступает в модель
                    "role": "user",
                    "content": f"Вопрос: {request}\nКонтекст: {help_information}\nОтветь своими словами."
                }
            ],
            temperature=0.2,
            max_tokens=500,
        )

        return response.choices[0].message.content

    except Exception as e:
        return f"Произошла ошибка: {str(e)}"

# Функция для получения ответа на основе названия дисциплины и запроса
def get_answer_api(d_name, message):
    document = answer_information(d_name, message)
    return llm_inference(message, document).replace('**', '').replace('[', '').replace(']', ' ') # Дополнительная обработка выдачи для избежания ошибок разметки

get_answer_api('Цифровая грамотность', 'сколько минут длится экзамен?')

"""## **Создание чат-бота**"""

from aiogram import Bot, Dispatcher, types
import logging
import asyncio
from aiogram.filters import Command
from aiogram.types import ReplyKeyboardMarkup, KeyboardButton
from aiogram.utils.keyboard import ReplyKeyboardBuilder
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup

# Настройка логирования
logging.basicConfig(level=logging.INFO)

# Инициализация бота
bot = Bot(token='token') # Вместо token вставляется токен конкретного чат-бота. Удален в целях безопасности
dp = Dispatcher()

# Состояния для FSM
class Form(StatesGroup):
    waiting_for_discipline = State()
    waiting_for_question = State()
    in_conversation = State()  # Новое состояние для продолжения диалога

# Кнопки для удобного общения
main_kb = [[
    KeyboardButton(text="Пожаловаться"),
    KeyboardButton(text="Выбрать дисциплину")
]]

# Кнопки для выбора дисциплины
disciplines_kb = [
    [KeyboardButton(text="Цифровая грамотность")],
    [KeyboardButton(text="Программирование на Python")],
    [KeyboardButton(text="Анализ данных")]
]

# Кнопки для продолжения диалога
continue_kb = [
    [KeyboardButton(text="Задать еще вопрос")],
    [KeyboardButton(text="Сменить дисциплину")],
    [KeyboardButton(text="Пожаловаться")]
]

# Интерфейс с кнопками
main_keyboard = ReplyKeyboardMarkup(
    keyboard=main_kb,
    resize_keyboard=True,
    input_field_placeholder="Выберите действие"
)

disciplines_keyboard = ReplyKeyboardMarkup(
    keyboard=disciplines_kb,
    resize_keyboard=True,
    input_field_placeholder="Выберите дисциплину"
)

continue_keyboard = ReplyKeyboardMarkup(
    keyboard=continue_kb,
    resize_keyboard=True,
    input_field_placeholder="Выберите действие"
)

# Обрабатываем команду "/start"
@dp.message(Command("start"))
async def start_command(message: types.Message):
    await message.answer(
        "Привет! Я Даташа, помощник ассистентов на курсах Цифровая грамотность, Основы программирования на Python и Анализ данных:) "
        "Я могу сориентировать вас, если возникнет какая-то проблема, "
        "поэтому не стесняйтесь обращаться!",
        reply_markup=main_keyboard
    )

# Обработка кнопки "Выбрать дисциплину"
@dp.message(lambda message: message.text == "Выбрать дисциплину")
async def choose_discipline(message: types.Message, state: FSMContext):
    await message.answer("Пожалуйста, выберите дисциплину:", reply_markup=disciplines_keyboard)
    await state.set_state(Form.waiting_for_discipline)

# Обработка выбора дисциплины
@dp.message(Form.waiting_for_discipline)
async def process_discipline(message: types.Message, state: FSMContext):
    disciplines = ["Цифровая грамотность", "Программирование на Python", "Анализ данных"]

    await state.update_data(discipline=message.text)
    await message.answer("Какой вопрос вас интересует?", reply_markup=types.ReplyKeyboardRemove())
    await state.set_state(Form.waiting_for_question)

# Обработка вопроса пользователя
@dp.message(Form.waiting_for_question)
async def process_question(message: types.Message, state: FSMContext):
    user_data = await state.get_data()
    discipline = user_data.get('discipline')
    question = message.text.strip()

    try:
        logging.info(f"Получен вопрос по дисциплине {discipline}: {question}")
        answer = get_answer_api(discipline, question)  # Отправляем запрос в LLM
        await message.answer(answer, reply_markup=continue_keyboard)
        await state.set_state(Form.in_conversation)  # Переходим в состояние продолжения диалога
    except Exception as e:
        logging.error(f"Ошибка при обработке вопроса: {e}")
        await message.answer(
            "Что-то я немного запуталась:( Не могли бы вы, пожалуйста, сформулировать вопрос иначе?",
            reply_markup=continue_keyboard
        )
        await state.set_state(Form.in_conversation)

# Обработка продолжения диалога
@dp.message(Form.in_conversation)
async def continue_conversation(message: types.Message, state: FSMContext):
    if message.text == "Задать еще вопрос":
        user_data = await state.get_data()
        discipline = user_data.get('discipline')
        await message.answer(f"Какой вопрос вас интересует?", reply_markup=types.ReplyKeyboardRemove())
        await state.set_state(Form.waiting_for_question)
    elif message.text == "Сменить дисциплину":
        await message.answer("Выберите новую дисциплину:", reply_markup=disciplines_keyboard)
        await state.set_state(Form.waiting_for_discipline)
    elif message.text == "Пожаловаться":
        await complain(message)
    else:
        # Если пользователь просто отправил текст, считаем это новым вопросом по текущей дисциплине
        await process_question(message, state)

# Обрабатываем кнопку "Пожаловаться"
@dp.message(lambda message: message.text == "Пожаловаться")
async def complain(message: types.Message):
    await message.answer(
        "Простите, что не смогла вам помочь:( Пожалуйста, заполните форму, "
        "чтобы в следующий раз я справилась лучше! "
        "https://docs.google.com/forms/d/e/1FAIpQLSdMLUrAXL9dMDOVbHllXcXuFbjM17b9CsfIzroi7Tl0x5mowQ/viewform?usp=dialog",
        reply_markup=main_keyboard
    )

# Запуск бота
async def main():
    await dp.start_polling(bot)

if __name__ == "__main__":
    # Проверяем, есть ли уже запущенный event loop
    try:
        loop = asyncio.get_running_loop()
    except RuntimeError:  # Если нет запущенного loop
        loop = None

    if loop and loop.is_running():
        # Если loop уже запущен (например, в Jupyter), создаем task
        task = loop.create_task(main())
        try:
            # В некоторых средах можно использовать asyncio.run_coroutine_threadsafe
            asyncio.run_coroutine_threadsafe(main(), loop)
        except:
            pass
    else:
        # Стандартный запуск
        asyncio.run(main())